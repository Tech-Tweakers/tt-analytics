import requests
import json
import pandas as pd
import matplotlib.pyplot as plt
from collections import defaultdict
from datetime import datetime, timedelta
import os

GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
OWNER = os.getenv("OWNER")
REPO = os.getenv("REPO")
THRESHOLD = os.getenv("THRESHOLD")
REWORK_DAYS = 21
HEADERS = {"Authorization": f"token {GITHUB_TOKEN}"}

json_file = f"rework_analysis_{REPO}.json"


def load_json(filename):
    """Carrega JSON existente ou cria um novo como uma lista vazia."""
    if os.path.exists(filename) and os.path.getsize(filename) > 0:
        with open(filename, "r") as f:
            try:
                data = json.load(f)
                if isinstance(data, list):
                    return data  
                else:
                    print(f"âš ï¸ {filename} estava no formato errado. Recriando...")
            except json.JSONDecodeError:
                print(f"âš ï¸ Erro ao carregar {filename}, recriando arquivo...")

    with open(filename, "w") as f:
        json.dump([], f, indent=4)
    return []  


def save_json(filename, data):
    """Salva os dados no JSON."""
    with open(filename, "w") as f:
        json.dump(data, f, indent=4)


def get_commits(owner, repo, branch):
    """ObtÃ©m a lista completa de commits do branch."""
    url = f"https://api.github.com/repos/{owner}/{repo}/commits"
    params = {"sha": branch, "per_page": 100}
    commits = []

    print(f"ğŸ“¥ Buscando commits no branch '{branch}' de {owner}/{repo}...")

    while url:
        response = requests.get(url, headers=HEADERS, params=params)

        if response.status_code != 200:
            raise Exception(f"âŒ Erro ao buscar commits: {response.json()}")

        data = response.json()
        commits.extend(data)

        url = response.links.get("next", {}).get("url")

    print(f"âœ… {len(commits)} commits encontrados!")
    return commits


def get_commit_changes(owner, repo, sha):
    """ObtÃ©m os arquivos e linhas modificadas em um commit."""
    url = f"https://api.github.com/repos/{owner}/{repo}/commits/{sha}"
    response = requests.get(url, headers=HEADERS)

    if response.status_code != 200:
        print(f"âš ï¸ Falha ao buscar detalhes do commit {sha}")
        return None

    data = response.json()
    files = data.get("files", [])

    changes = {}
    for file in files:
        filename = file["filename"]
        patch = file.get("patch", "")

        if patch:
            changed_lines = set()
            for line in patch.split("\n"):
                if line.startswith("+") and not line.startswith("+++"):  # Linhas adicionadas
                    changed_lines.add(line)
                elif line.startswith("-") and not line.startswith("---"):  # Linhas removidas
                    changed_lines.add(line)

            changes[filename] = changed_lines

    return changes


def analyze_rework(commits):
    """Analisa commits e salva no JSON."""
    rework_data = load_json(json_file)  # Agora sempre retorna uma lista
    existing_data = {entry["sha"]: entry for entry in rework_data}  # Dict de commits jÃ¡ analisados

    total_rework_rate = 0
    total_rework_rate_recent = 0
    total_commits = 0

    total_lines_analyzed = 0
    total_lines_rework = 0
    total_lines_rework_recent = 0

    for i, commit in enumerate(commits, 1):
        sha = commit["sha"]
        date = commit["commit"]["author"]["date"]
        commit_date = datetime.strptime(date, "%Y-%m-%dT%H:%M:%SZ")

        if sha in existing_data:
            print(f"ğŸ”„ Commit {sha[:7]} jÃ¡ existe no JSON. Usando dados armazenados...")
            commit_data = existing_data[sha]
        else:
            print(f"\nğŸ”¹ [{i}/{len(commits)}] Processando commit {sha[:7]} ({date})")

            changes = get_commit_changes(OWNER, REPO, sha)
            if not changes:
                continue

            total_changes = sum(len(lines) for lines in changes.values())

            rework_changes_total = sum(
                1
                for file in changes
                for line in changes[file]
                if len(changes[file]) >= int(THRESHOLD)
            )
            rework_changes_recent = sum(
                1
                for file in changes
                for line in changes[file]
                if len(changes[file]) >= int(THRESHOLD)
                and commit_date >= datetime.utcnow() - timedelta(days=REWORK_DAYS)
            )

            rework_rate_total = (
                (rework_changes_total / total_changes) * 100 if total_changes > 0 else 0
            )
            rework_rate_recent = (
                (rework_changes_recent / total_changes) * 100 if total_changes > 0 else 0
            )

            commit_data = {
                "data": date[:10],  
                "sha": sha,
                "total_changes": total_changes,
                "rework_changes_total": rework_changes_total,
                "rework_rate_total": rework_rate_total,
                "rework_changes_recent": rework_changes_recent,
                "rework_rate_recent": rework_rate_recent,
                "arquivos_modificados": list(changes.keys()),
            }

            rework_data.append(commit_data)

        # Somando os resultados para o print final
        total_rework_rate += commit_data["rework_rate_total"]
        total_rework_rate_recent += commit_data["rework_rate_recent"]
        total_commits += 1

        total_lines_analyzed += commit_data["total_changes"]
        total_lines_rework += commit_data["rework_changes_total"]
        total_lines_rework_recent += commit_data["rework_changes_recent"]

    save_json(json_file, rework_data)
    print(f"ğŸ“Š JSON atualizado com histÃ³rico completo de commits: {json_file}")

    # Exibir as mÃ©tricas no final
    if total_commits > 0:
        average_rework_rate = total_rework_rate / total_commits
        average_rework_rate_recent = total_rework_rate_recent / total_commits

        print("\nğŸ“Š **RESULTADOS FINAIS:**")
        print(f"ğŸ”¹ Total de Commits analisados: {total_commits}")
        print(f"ğŸ”¹ Total de Linhas Analisadas: {total_lines_analyzed}")
        print(f"ğŸ”¹ Total de Linhas de Retrabalho: {total_lines_rework}")
        print(f"ğŸ”¹ Total de Linhas de Retrabalho nos Ãºltimos {REWORK_DAYS} dias: {total_lines_rework_recent}")
        print(f"ğŸ”¹ Rework Rate Geral: {average_rework_rate:.2f}%")
        print(f"ğŸ”¹ Rework Rate nos Ãºltimos {REWORK_DAYS} dias: {average_rework_rate_recent:.2f}%")
    else:
        print("âš ï¸ Nenhum commit foi analisado.")


def load_json(filename):
    """Carrega os dados do JSON."""
    with open(filename, "r") as f:
        return json.load(f)


def generate_graph():
    """Gera dois grÃ¡ficos separados para rework_rate_total e rework_rate_recent, alÃ©m de incluir um box com mÃ©tricas."""
    rework_data = load_json(json_file)

    # ğŸ“Œ Criar um DataFrame a partir dos dados
    df = pd.DataFrame(rework_data)

    # ğŸ“Œ Converter a data para formato datetime e ordenar
    df["data"] = pd.to_datetime(df["data"])
    df = df.sort_values("data")

    # ğŸ“Œ Remover duplicatas mantendo o Ãºltimo valor registrado para cada data
    df = df.drop_duplicates(subset="data", keep="last")

    # ğŸ“Œ Gerar mÃ©tricas finais
    total_commits = len(df)
    total_lines_analyzed = df["total_changes"].sum()
    total_lines_rework = df["rework_changes_total"].sum()
    total_lines_rework_recent = df["rework_changes_recent"].sum()
    average_rework_rate = df["rework_rate_total"].mean()
    average_rework_rate_recent = df["rework_rate_recent"].mean()

    # ğŸ“Š Criando grÃ¡ficos separados
    fig, axes = plt.subplots(2, 1, figsize=(12, 10), sharex=True)

    # ğŸ“Œ GrÃ¡fico 1: Rework Rate Total
    axes[0].plot(df["data"], df["rework_rate_total"], marker="o", linestyle="-", color="b", label="Rework Rate Geral")
    axes[0].set_ylabel("Rework Rate (%)")
    axes[0].set_title("EvoluÃ§Ã£o do Rework Rate Geral")
    axes[0].grid()
    axes[0].legend()

    # ğŸ“Œ GrÃ¡fico 2: Rework Rate Recent (Ãšltimos 21 dias)
    axes[1].plot(df["data"], df["rework_rate_recent"], marker="o", linestyle="--", color="r", label="Rework Rate (Ãšltimos 21 dias)")
    axes[1].set_xlabel("Data")
    axes[1].set_ylabel("Rework Rate (%)")
    axes[1].set_title(f"EvoluÃ§Ã£o do Rework Rate nos Ãºltimos {REWORK_DAYS} dias")
    axes[1].grid()
    axes[1].legend()

    # ğŸ“Œ Melhorar visualizaÃ§Ã£o do eixo X
    axes[1].set_xticks(df["data"][:: max(1, len(df) // 10)])
    plt.xticks(rotation=45)

    # ğŸ“Œ Adicionar box com mÃ©tricas
    metrics_text = (
        f"ğŸ”¹ Total de Commits: {total_commits}\n"
        f"ğŸ”¹ Total de Linhas Analisadas: {total_lines_analyzed}\n"
        f"ğŸ”¹ Total de Linhas de Retrabalho: {total_lines_rework}\n"
        f"ğŸ”¹ Linhas de Retrabalho (Ãšltimos {REWORK_DAYS} dias): {total_lines_rework_recent}\n"
        f"ğŸ”¹ Rework Rate Geral: {average_rework_rate:.2f}%\n"
        f"ğŸ”¹ Rework Rate (Ãšltimos {REWORK_DAYS} dias): {average_rework_rate_recent:.2f}%"
    )

    plt.gcf().text(0.15, 0.02, metrics_text, fontsize=10, bbox=dict(facecolor="white", alpha=0.8, edgecolor="black"))

    # ğŸ“Œ Destacar picos de retrabalho
    max_total_idx = df["rework_rate_total"].idxmax()
    max_recent_idx = df["rework_rate_recent"].idxmax()

    if not df.empty:
        axes[0].annotate(f"{df['rework_rate_total'].max():.2f}%", 
                         xy=(df["data"][max_total_idx], df["rework_rate_total"].max()), 
                         xytext=(df["data"][max_total_idx], df["rework_rate_total"].max() + 5),
                         arrowprops=dict(facecolor='blue', arrowstyle='->'))
        
        axes[1].annotate(f"{df['rework_rate_recent'].max():.2f}%", 
                         xy=(df["data"][max_recent_idx], df["rework_rate_recent"].max()), 
                         xytext=(df["data"][max_recent_idx], df["rework_rate_recent"].max() + 5),
                         arrowprops=dict(facecolor='red', arrowstyle='->'))

    # ğŸ“Œ Salvar grÃ¡ficos
    plt.tight_layout()
    plt.savefig("rework_rate_analysis.png", dpi=300)
    print("ğŸ“Š GrÃ¡ficos salvos como rework_rate_analysis.png")


if __name__ == "__main__":
    commits = get_commits(OWNER, REPO, "main")
    analyze_rework(commits)
    generate_graph()
