import requests
import json
import pandas as pd
import matplotlib.pyplot as plt
from collections import defaultdict
from datetime import datetime, timedelta
import os

GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
OWNER = os.getenv("OWNER")
REPO = os.getenv("REPO")
THRESHOLD = os.getenv("THRESHOLD")
REWORK_DAYS = 21
HEADERS = {"Authorization": f"token {GITHUB_TOKEN}"}

json_file = f"rework_analysis_{REPO}.json"


def load_json(filename):
    """Carrega JSON existente ou cria um novo como uma lista vazia."""
    if os.path.exists(filename) and os.path.getsize(filename) > 0:
        with open(filename, "r") as f:
            try:
                data = json.load(f)
                if isinstance(data, list):
                    return data  
                else:
                    print(f"âš ï¸ {filename} estava no formato errado. Recriando...")
            except json.JSONDecodeError:
                print(f"âš ï¸ Erro ao carregar {filename}, recriando arquivo...")

    with open(filename, "w") as f:
        json.dump([], f, indent=4)
    return []  


def save_json(filename, data):
    """Salva os dados no JSON."""
    with open(filename, "w") as f:
        json.dump(data, f, indent=4)


def get_commits(owner, repo, branch):
    """ObtÃ©m a lista completa de commits do branch."""
    url = f"https://api.github.com/repos/{owner}/{repo}/commits"
    params = {"sha": branch, "per_page": 100}
    commits = []

    print(f"ğŸ“¥ Buscando commits no branch '{branch}' de {owner}/{repo}...")

    while url:
        response = requests.get(url, headers=HEADERS, params=params)

        if response.status_code != 200:
            raise Exception(f"âŒ Erro ao buscar commits: {response.json()}")

        data = response.json()
        commits.extend(data)

        url = response.links.get("next", {}).get("url")

    print(f"âœ… {len(commits)} commits encontrados!")
    return commits


def get_commit_changes(owner, repo, sha):
    """ObtÃ©m os arquivos e linhas modificadas em um commit."""
    url = f"https://api.github.com/repos/{owner}/{repo}/commits/{sha}"
    response = requests.get(url, headers=HEADERS)

    if response.status_code != 200:
        print(f"âš ï¸ Falha ao buscar detalhes do commit {sha}")
        return None

    data = response.json()
    files = data.get("files", [])

    changes = {}
    for file in files:
        filename = file["filename"]
        patch = file.get("patch", "")

        if patch:
            changed_lines = set()
            for line in patch.split("\n"):
                if line.startswith("+") and not line.startswith("+++"):  # Linhas adicionadas
                    changed_lines.add(line)
                elif line.startswith("-") and not line.startswith("---"):  # Linhas removidas
                    changed_lines.add(line)

            changes[filename] = changed_lines

    return changes


def analyze_rework(commits):
    """Analisa commits e salva no JSON."""
    rework_data = load_json(json_file)  # Agora sempre retorna uma lista
    existing_data = {entry["sha"]: entry for entry in rework_data}  # Dict de commits jÃ¡ analisados

    total_rework_rate = 0
    total_rework_rate_recent = 0
    total_commits = 0

    total_lines_analyzed = 0
    total_lines_rework = 0
    total_lines_rework_recent = 0

    for i, commit in enumerate(commits, 1):
        sha = commit["sha"]
        date = commit["commit"]["author"]["date"]
        commit_date = datetime.strptime(date, "%Y-%m-%dT%H:%M:%SZ")

        if sha in existing_data:
            print(f"ğŸ”„ Commit {sha[:7]} jÃ¡ existe no JSON. Usando dados armazenados...")
            commit_data = existing_data[sha]
        else:
            print(f"\nğŸ”¹ [{i}/{len(commits)}] Processando commit {sha[:7]} ({date})")

            changes = get_commit_changes(OWNER, REPO, sha)
            if not changes:
                continue

            total_changes = sum(len(lines) for lines in changes.values())

            rework_changes_total = sum(
                1
                for file in changes
                for line in changes[file]
                if len(changes[file]) >= int(THRESHOLD)
            )
            rework_changes_recent = sum(
                1
                for file in changes
                for line in changes[file]
                if len(changes[file]) >= int(THRESHOLD)
                and commit_date >= datetime.utcnow() - timedelta(days=REWORK_DAYS)
            )

            rework_rate_total = (
                (rework_changes_total / total_changes) * 100 if total_changes > 0 else 0
            )
            rework_rate_recent = (
                (rework_changes_recent / total_changes) * 100 if total_changes > 0 else 0
            )

            commit_data = {
                "data": date[:10],  
                "sha": sha,
                "total_changes": total_changes,
                "rework_changes_total": rework_changes_total,
                "rework_rate_total": rework_rate_total,
                "rework_changes_recent": rework_changes_recent,
                "rework_rate_recent": rework_rate_recent,
                "arquivos_modificados": list(changes.keys()),
            }

            rework_data.append(commit_data)

        # Somando os resultados para o print final
        total_rework_rate += commit_data["rework_rate_total"]
        total_rework_rate_recent += commit_data["rework_rate_recent"]
        total_commits += 1

        total_lines_analyzed += commit_data["total_changes"]
        total_lines_rework += commit_data["rework_changes_total"]
        total_lines_rework_recent += commit_data["rework_changes_recent"]

    save_json(json_file, rework_data)
    print(f"ğŸ“Š JSON atualizado com histÃ³rico completo de commits: {json_file}")

    # Exibir as mÃ©tricas no final
    if total_commits > 0:
        average_rework_rate = total_rework_rate / total_commits
        average_rework_rate_recent = total_rework_rate_recent / total_commits

        print("\nğŸ“Š **RESULTADOS FINAIS:**")
        print(f"ğŸ”¹ Total de Commits analisados: {total_commits}")
        print(f"ğŸ”¹ Total de Linhas Analisadas: {total_lines_analyzed}")
        print(f"ğŸ”¹ Total de Linhas de Retrabalho: {total_lines_rework}")
        print(f"ğŸ”¹ Total de Linhas de Retrabalho nos Ãºltimos {REWORK_DAYS} dias: {total_lines_rework_recent}")
        print(f"ğŸ”¹ Rework Rate Geral: {average_rework_rate:.2f}%")
        print(f"ğŸ”¹ Rework Rate nos Ãºltimos {REWORK_DAYS} dias: {average_rework_rate_recent:.2f}%")
    else:
        print("âš ï¸ Nenhum commit foi analisado.")


# def load_json(filename):
#     """Carrega os dados do JSON."""
#     with open(filename, "r") as f:
#         return json.load(f)


# def generate_graph():
#     """Gera um grÃ¡fico com base no JSON existente."""
#     rework_data = load_json(json_file)

#     # ğŸ“Œ Criar um DataFrame a partir dos dados
#     df = pd.DataFrame(rework_data)

#     # ğŸ“Œ Converter a data para formato datetime e ordenar
#     df["data"] = pd.to_datetime(df["data"])
#     df = df.sort_values("data")

#     # ğŸ“Œ Remover duplicatas mantendo o Ãºltimo valor registrado para cada data
#     df = df.drop_duplicates(subset="data", keep="last")

#     # ğŸ“Œ Criar um intervalo contÃ­nuo de datas desde o primeiro commit atÃ© hoje
#     date_range = pd.date_range(
#         start=df["data"].min(), end=datetime.utcnow().strftime("%Y-%m-%d")
#     )

#     # ğŸ“Œ Preencher dias vazios com o Ãºltimo valor conhecido
#     df = df.set_index("data").reindex(date_range, method="ffill").reset_index()
#     df.rename(columns={"index": "data"}, inplace=True)
#     df["data"] = df["data"].dt.strftime("%Y-%m-%d")

#     # ğŸ“Œ Aplicar mÃ©dia mÃ³vel para suavizar oscilaÃ§Ãµes extremas
#     df["rework_rate_total"] = (
#         df["rework_rate_total"].rolling(window=3, min_periods=1).mean()
#     )
#     df["rework_rate_recent"] = (
#         df["rework_rate_recent"].rolling(window=3, min_periods=1).mean()
#     )

#     # ğŸ“Š Criar o grÃ¡fico
#     plt.figure(figsize=(12, 6))
#     plt.plot(
#         df["data"],
#         df["rework_rate_total"],
#         marker="o",
#         linestyle="-",
#         color="b",
#         label="Rework Rate Geral",
#     )
#     plt.plot(
#         df["data"],
#         df["rework_rate_recent"],
#         marker="o",
#         linestyle="--",
#         color="r",
#         label="Rework Rate (Ãšltimos 21 dias)",
#     )

#     # ğŸ“Œ Melhorar visualizaÃ§Ã£o do eixo X
#     plt.xticks(rotation=45, ticks=df["data"][:: max(1, len(df) // 10)])

#     # ğŸ“Œ Labels e tÃ­tulo
#     plt.xlabel("Data")
#     plt.ylabel("Rework Rate (%)")
#     plt.title("EvoluÃ§Ã£o do Rework Rate ao longo do tempo")
#     plt.grid()
#     plt.legend()

#     # ğŸ“Œ Salvar grÃ¡fico
#     plt.savefig("rework_rate.png", dpi=300)
#     print("ğŸ“Š GrÃ¡fico salvo como rework_rate.png")


if __name__ == "__main__":
    commits = get_commits(OWNER, REPO, "main")
    analyze_rework(commits)
    # generate_graph()
